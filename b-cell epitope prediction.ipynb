{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5d72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e422cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab65850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_pos</th>\n",
       "      <th>Info_host_id</th>\n",
       "      <th>Info_group</th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_Entropy</th>\n",
       "      <th>feat_MolWeight</th>\n",
       "      <th>feat_AAtypes_Tiny</th>\n",
       "      <th>feat_AAtypes_Small</th>\n",
       "      <th>feat_AAtypes_Aliphatic</th>\n",
       "      <th>feat_AAtypes_Aromatic</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm2_1271</th>\n",
       "      <th>feat_esm2_1272</th>\n",
       "      <th>feat_esm2_1273</th>\n",
       "      <th>feat_esm2_1274</th>\n",
       "      <th>feat_esm2_1275</th>\n",
       "      <th>feat_esm2_1276</th>\n",
       "      <th>feat_esm2_1277</th>\n",
       "      <th>feat_esm2_1278</th>\n",
       "      <th>feat_esm2_1279</th>\n",
       "      <th>feat_esm2_1280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>319.781111</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>129.960289</td>\n",
       "      <td>-0.985244</td>\n",
       "      <td>2.963995</td>\n",
       "      <td>1883.791208</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.574204</td>\n",
       "      <td>0.280793</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>-0.053453</td>\n",
       "      <td>0.028602</td>\n",
       "      <td>-0.046709</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>0.062953</td>\n",
       "      <td>-0.043011</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>275.101398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.204808</td>\n",
       "      <td>0.171155</td>\n",
       "      <td>0.385034</td>\n",
       "      <td>148.303010</td>\n",
       "      <td>0.159486</td>\n",
       "      <td>0.175301</td>\n",
       "      <td>0.152201</td>\n",
       "      <td>0.079166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152642</td>\n",
       "      <td>0.139088</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.154066</td>\n",
       "      <td>0.134989</td>\n",
       "      <td>0.153164</td>\n",
       "      <td>0.140340</td>\n",
       "      <td>0.153867</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.150673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>1198.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.702291</td>\n",
       "      <td>-0.777684</td>\n",
       "      <td>-0.711707</td>\n",
       "      <td>-0.534939</td>\n",
       "      <td>-0.776880</td>\n",
       "      <td>-0.822042</td>\n",
       "      <td>-0.581313</td>\n",
       "      <td>-0.840151</td>\n",
       "      <td>-0.791998</td>\n",
       "      <td>-0.601091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.789898</td>\n",
       "      <td>1788.850000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056009</td>\n",
       "      <td>-0.066439</td>\n",
       "      <td>-0.130491</td>\n",
       "      <td>-0.077223</td>\n",
       "      <td>-0.132446</td>\n",
       "      <td>-0.141362</td>\n",
       "      <td>-0.029193</td>\n",
       "      <td>-0.135852</td>\n",
       "      <td>-0.053991</td>\n",
       "      <td>-0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.006239</td>\n",
       "      <td>1886.910000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043914</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>-0.050389</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>-0.045311</td>\n",
       "      <td>-0.039615</td>\n",
       "      <td>0.064743</td>\n",
       "      <td>-0.036643</td>\n",
       "      <td>0.059092</td>\n",
       "      <td>0.095492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>424.000000</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.189898</td>\n",
       "      <td>1986.180000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141148</td>\n",
       "      <td>0.106192</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>0.125858</td>\n",
       "      <td>0.037470</td>\n",
       "      <td>0.057832</td>\n",
       "      <td>0.156408</td>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.166234</td>\n",
       "      <td>0.190922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1658.000000</td>\n",
       "      <td>9606.0</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.906891</td>\n",
       "      <td>2415.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765174</td>\n",
       "      <td>0.604259</td>\n",
       "      <td>0.616022</td>\n",
       "      <td>0.894539</td>\n",
       "      <td>0.682663</td>\n",
       "      <td>0.793851</td>\n",
       "      <td>0.754429</td>\n",
       "      <td>0.672107</td>\n",
       "      <td>0.716797</td>\n",
       "      <td>0.896703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1639 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Info_pos  Info_host_id    Info_group         Class  feat_Entropy  \\\n",
       "count  45000.000000       45000.0  45000.000000  45000.000000  45000.000000   \n",
       "mean     319.781111        9606.0    129.960289     -0.985244      2.963995   \n",
       "std      275.101398           0.0    100.204808      0.171155      0.385034   \n",
       "min        1.000000        9606.0      9.000000     -1.000000      0.699843   \n",
       "25%      120.000000        9606.0     42.000000     -1.000000      2.789898   \n",
       "50%      243.000000        9606.0    103.000000     -1.000000      3.006239   \n",
       "75%      424.000000        9606.0    191.000000     -1.000000      3.189898   \n",
       "max     1658.000000        9606.0    376.000000      1.000000      3.906891   \n",
       "\n",
       "       feat_MolWeight  feat_AAtypes_Tiny  feat_AAtypes_Small  \\\n",
       "count    45000.000000       45000.000000        45000.000000   \n",
       "mean      1883.791208           0.354167            0.574204   \n",
       "std        148.303010           0.159486            0.175301   \n",
       "min       1198.130000           0.000000            0.000000   \n",
       "25%       1788.850000           0.266667            0.466667   \n",
       "50%       1886.910000           0.333333            0.600000   \n",
       "75%       1986.180000           0.466667            0.666667   \n",
       "max       2415.760000           1.000000            1.000000   \n",
       "\n",
       "       feat_AAtypes_Aliphatic  feat_AAtypes_Aromatic  ...  feat_esm2_1271  \\\n",
       "count            45000.000000           45000.000000  ...    45000.000000   \n",
       "mean                 0.280793               0.072588  ...        0.038835   \n",
       "std                  0.152201               0.079166  ...        0.152642   \n",
       "min                  0.000000               0.000000  ...       -0.702291   \n",
       "25%                  0.200000               0.000000  ...       -0.056009   \n",
       "50%                  0.266667               0.066667  ...        0.043914   \n",
       "75%                  0.333333               0.133333  ...        0.141148   \n",
       "max                  1.000000               0.533333  ...        0.765174   \n",
       "\n",
       "       feat_esm2_1272  feat_esm2_1273  feat_esm2_1274  feat_esm2_1275  \\\n",
       "count    45000.000000    45000.000000    45000.000000    45000.000000   \n",
       "mean         0.014660       -0.053453        0.028602       -0.046709   \n",
       "std          0.139088        0.129500        0.154066        0.134989   \n",
       "min         -0.777684       -0.711707       -0.534939       -0.776880   \n",
       "25%         -0.066439       -0.130491       -0.077223       -0.132446   \n",
       "50%          0.023128       -0.050389        0.021100       -0.045311   \n",
       "75%          0.106192        0.028364        0.125858        0.037470   \n",
       "max          0.604259        0.616022        0.894539        0.682663   \n",
       "\n",
       "       feat_esm2_1276  feat_esm2_1277  feat_esm2_1278  feat_esm2_1279  \\\n",
       "count    45000.000000    45000.000000    45000.000000    45000.000000   \n",
       "mean        -0.041111        0.062953       -0.043011        0.052560   \n",
       "std          0.153164        0.140340        0.153867        0.167224   \n",
       "min         -0.822042       -0.581313       -0.840151       -0.791998   \n",
       "25%         -0.141362       -0.029193       -0.135852       -0.053991   \n",
       "50%         -0.039615        0.064743       -0.036643        0.059092   \n",
       "75%          0.057832        0.156408        0.056991        0.166234   \n",
       "max          0.793851        0.754429        0.672107        0.716797   \n",
       "\n",
       "       feat_esm2_1280  \n",
       "count    45000.000000  \n",
       "mean         0.093800  \n",
       "std          0.150673  \n",
       "min         -0.601091  \n",
       "25%         -0.003531  \n",
       "50%          0.095492  \n",
       "75%          0.190922  \n",
       "max          0.896703  \n",
       "\n",
       "[8 rows x 1639 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281a378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45000 entries, 0 to 44999\n",
      "Columns: 1650 entries, Info_PepID to feat_esm2_1280\n",
      "dtypes: float64(1628), int64(11), object(11)\n",
      "memory usage: 566.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75bf801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8838bc0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e41901c7f5ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Dataset shape: {df.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeat_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'feat_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minfo_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Info_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Features: {len(feat_cols)}, Info columns: {len(info_cols)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "feat_cols = [col for col in df.columns if col.startswith('feat_')]\n",
    "info_cols = [col for col in df.columns if col.startswith('Info_')]\n",
    "print(f\"Features: {len(feat_cols)}, Info columns: {len(info_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9195f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    44668\n",
      " 1      332\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = df['Class'].value_counts()\n",
    "print(class_counts)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f4ae0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_Entropy</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>2.963995</td>\n",
       "      <td>0.385034</td>\n",
       "      <td>0.699843</td>\n",
       "      <td>2.789898</td>\n",
       "      <td>3.006239</td>\n",
       "      <td>3.189898</td>\n",
       "      <td>3.906891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_MolWeight</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>1883.791208</td>\n",
       "      <td>148.303010</td>\n",
       "      <td>1198.130000</td>\n",
       "      <td>1788.850000</td>\n",
       "      <td>1886.910000</td>\n",
       "      <td>1986.180000</td>\n",
       "      <td>2415.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_AAtypes_Tiny</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.159486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_AAtypes_Small</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.574204</td>\n",
       "      <td>0.175301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_AAtypes_Aliphatic</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.280793</td>\n",
       "      <td>0.152201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_esm2_1276</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>0.153164</td>\n",
       "      <td>-0.822042</td>\n",
       "      <td>-0.141362</td>\n",
       "      <td>-0.039615</td>\n",
       "      <td>0.057832</td>\n",
       "      <td>0.793851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_esm2_1277</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.062953</td>\n",
       "      <td>0.140340</td>\n",
       "      <td>-0.581313</td>\n",
       "      <td>-0.029193</td>\n",
       "      <td>0.064743</td>\n",
       "      <td>0.156408</td>\n",
       "      <td>0.754429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_esm2_1278</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>-0.043011</td>\n",
       "      <td>0.153867</td>\n",
       "      <td>-0.840151</td>\n",
       "      <td>-0.135852</td>\n",
       "      <td>-0.036643</td>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.672107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_esm2_1279</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>-0.791998</td>\n",
       "      <td>-0.053991</td>\n",
       "      <td>0.059092</td>\n",
       "      <td>0.166234</td>\n",
       "      <td>0.716797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_esm2_1280</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.150673</td>\n",
       "      <td>-0.601091</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>0.095492</td>\n",
       "      <td>0.190922</td>\n",
       "      <td>0.896703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count         mean         std          min  \\\n",
       "feat_Entropy            45000.0     2.963995    0.385034     0.699843   \n",
       "feat_MolWeight          45000.0  1883.791208  148.303010  1198.130000   \n",
       "feat_AAtypes_Tiny       45000.0     0.354167    0.159486     0.000000   \n",
       "feat_AAtypes_Small      45000.0     0.574204    0.175301     0.000000   \n",
       "feat_AAtypes_Aliphatic  45000.0     0.280793    0.152201     0.000000   \n",
       "...                         ...          ...         ...          ...   \n",
       "feat_esm2_1276          45000.0    -0.041111    0.153164    -0.822042   \n",
       "feat_esm2_1277          45000.0     0.062953    0.140340    -0.581313   \n",
       "feat_esm2_1278          45000.0    -0.043011    0.153867    -0.840151   \n",
       "feat_esm2_1279          45000.0     0.052560    0.167224    -0.791998   \n",
       "feat_esm2_1280          45000.0     0.093800    0.150673    -0.601091   \n",
       "\n",
       "                                25%          50%          75%          max  \n",
       "feat_Entropy               2.789898     3.006239     3.189898     3.906891  \n",
       "feat_MolWeight          1788.850000  1886.910000  1986.180000  2415.760000  \n",
       "feat_AAtypes_Tiny          0.266667     0.333333     0.466667     1.000000  \n",
       "feat_AAtypes_Small         0.466667     0.600000     0.666667     1.000000  \n",
       "feat_AAtypes_Aliphatic     0.200000     0.266667     0.333333     1.000000  \n",
       "...                             ...          ...          ...          ...  \n",
       "feat_esm2_1276            -0.141362    -0.039615     0.057832     0.793851  \n",
       "feat_esm2_1277            -0.029193     0.064743     0.156408     0.754429  \n",
       "feat_esm2_1278            -0.135852    -0.036643     0.056991     0.672107  \n",
       "feat_esm2_1279            -0.053991     0.059092     0.166234     0.716797  \n",
       "feat_esm2_1280            -0.003531     0.095492     0.190922     0.896703  \n",
       "\n",
       "[1635 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols = [col for col in df.columns if col.startswith('feat_')]\n",
    "df[feat_cols].describe().T  # Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e694891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[feat_cols].describe().T\n",
    "plt.figure(figsize=(10, 6))\n",
    "df[feat_cols[:10]].boxplot()  # Sample first 10 features\n",
    "plt.title('Sample Feature Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e051aea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[feat_cols].describe().T\n",
    "plt.figure(figsize=(10, 6))\n",
    "df[feat_cols[:10]].boxplot()  # Sample first 10 features\n",
    "plt.title('Sample Feature Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f103120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_Entropy              729\n",
      "feat_MolWeight            208\n",
      "feat_AAtypes_Tiny         119\n",
      "feat_AAtypes_Small         16\n",
      "feat_AAtypes_Aliphatic    449\n",
      "                         ... \n",
      "feat_esm2_1276            272\n",
      "feat_esm2_1277            231\n",
      "feat_esm2_1278            329\n",
      "feat_esm2_1279            211\n",
      "feat_esm2_1280            303\n",
      "Length: 1601, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "z_scores = df[feat_cols].apply(zscore)\n",
    "print((z_scores.abs() > 3).sum()[lambda x: x > 0])  # Features with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71daeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\garvit\\anaconda3\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: boruta in c:\\users\\garvit\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from boruta) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from boruta) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from boruta) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->boruta) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->boruta) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a35bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (45000, 1635)\n",
      "Original class distribution:\n",
      "-1    44668\n",
      " 1      332\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Resampled dataset shape: (89336, 1635)\n",
      "Resampled class distribution:\n",
      " 1    44668\n",
      "-1    44668\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X = df.loc[:, df.columns.str.startswith('feat_')]\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"Original dataset shape: {X.shape}\")\n",
    "print(f\"Original class distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "# Configure and apply SMOTE\n",
    "# k_neighbors might need adjustment if you have fewer than 5 positive samples\n",
    "smote = SMOTE(random_state=42, k_neighbors=4) \n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(f\"\\nResampled dataset shape: {X_resampled.shape}\")\n",
    "print(f\"Resampled class distribution:\\n{y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac0d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected top 200 features based on Mutual Information.\n",
      "Reduced feature set shape: (89336, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Calculate Mutual Information scores for each feature\n",
    "mi_scores = mutual_info_classif(X_resampled, y_resampled, random_state=42)\n",
    "mi_scores_series = pd.Series(mi_scores, index=X_resampled.columns, name='MI_Score')\n",
    "mi_scores_series = mi_scores_series.sort_values(ascending=False)\n",
    "\n",
    "# Select the top 200 features\n",
    "top_k = 200\n",
    "top_features = mi_scores_series.head(top_k).index.tolist()\n",
    "X_reduced = X_resampled[top_features]\n",
    "\n",
    "print(f\"\\nSelected top {top_k} features based on Mutual Information.\")\n",
    "print(f\"Reduced feature set shape: {X_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "397fea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 10\n",
      "Confirmed: \t0\n",
      "Tentative: \t200\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 10\n",
      "Confirmed: \t200\n",
      "Tentative: \t0\n",
      "Rejected: \t0\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t9 / 10\n",
      "Confirmed: \t200\n",
      "Tentative: \t0\n",
      "Rejected: \t0\n",
      "\n",
      "Boruta feature selection complete.\n",
      "Number of final features: 200\n",
      "Final feature set shape: (89336, 200)\n",
      "\n",
      "Final selected features:\n",
      "['feat_CTDD_prop6.G2.residue50', 'feat_Entropy', 'feat_CTDD_prop6.G2.residue100', 'feat_CTDD_prop6.G2.residue25', 'feat_CTDD_prop3.G1.residue75', 'feat_CTDD_prop6.G2.residue75', 'feat_CTDD_prop6.G2.residue0', 'feat_CTDD_prop1.G3.residue75', 'feat_CTDD_prop1.G3.residue50', 'feat_CTDD_prop3.G1.residue50', 'feat_CTDD_prop1.G3.residue100', 'feat_CTDD_prop3.G1.residue100', 'feat_CTDD_prop1.G3.residue25', 'feat_CTDD_prop3.G1.residue25', 'feat_CTDD_prop1.G3.residue0', 'feat_CTDD_prop3.G1.residue0', 'feat_CTDD_prop4.G3.residue75', 'feat_CTDD_prop2.G3.residue75', 'feat_CTDD_prop4.G3.residue50', 'feat_CTDD_prop2.G3.residue50', 'feat_CTDD_prop7.G3.residue75', 'feat_CTDD_prop2.G3.residue100', 'feat_CTDD_prop4.G3.residue100', 'feat_CTDD_prop2.G2.residue50', 'feat_CTDD_prop4.G3.residue25', 'feat_CTDD_prop2.G3.residue0', 'feat_CTDD_prop2.G3.residue25', 'feat_CTDD_prop4.G3.residue0', 'feat_CTDD_prop7.G3.residue50', 'feat_CTDD_prop2.G2.residue75', 'feat_CTDD_prop7.G2.residue50', 'feat_CTDD_prop1.G1.residue50', 'feat_CTDD_prop7.G1.residue50', 'feat_CTDD_prop5.G1.residue100', 'feat_CTDD_prop7.G2.residue75', 'feat_CTDD_prop3.G3.residue50', 'feat_CTDD_prop5.G3.residue75', 'feat_CTDD_prop1.G1.residue75', 'feat_CTDD_prop5.G1.residue0', 'feat_CTDD_prop5.G1.residue50', 'feat_CTDD_prop5.G1.residue25', 'feat_CTDD_prop5.G1.residue75', 'feat_CTDD_prop5.G3.residue100', 'feat_CTDD_prop6.G3.residue75', 'feat_CTDD_prop3.G2.residue50', 'feat_CTDT_prop1.Tr1221', 'feat_CTDD_prop7.G1.residue75', 'feat_CTDD_prop3.G3.residue75', 'feat_CTDD_prop7.G3.residue100', 'feat_CTDD_prop4.G2.residue75', 'feat_CTDD_prop1.G2.residue50', 'feat_CTDD_prop7.G3.residue25', 'feat_CTDD_prop2.G2.residue100', 'feat_CTDD_prop3.G2.residue75', 'feat_CTDD_prop6.G3.residue50', 'feat_CTDD_prop5.G3.residue50', 'feat_CTDD_prop2.G2.residue25', 'feat_CTDD_prop7.G3.residue0', 'feat_CTDD_prop6.G1.residue50', 'feat_CTDD_prop5.G3.residue25', 'feat_CTDD_prop1.G2.residue75', 'feat_CTDC_solventaccess.Group1', 'feat_CTDD_prop4.G2.residue50', 'feat_CTDT_prop7.Tr2332', 'feat_CTDT_prop3.Tr2332', 'feat_CTDD_prop6.G1.residue75', 'feat_CTDD_prop5.G3.residue0', 'feat_CTDD_prop7.G2.residue100', 'feat_CTDD_prop1.G1.residue100', 'feat_CTDD_prop6.G3.residue25', 'feat_CTDD_prop4.G1.residue50', 'feat_CTDD_prop4.G1.residue75', 'feat_CTDD_prop2.G2.residue0', 'feat_CTDD_prop6.G3.residue100', 'feat_CTDD_prop4.G2.residue100', 'feat_CTDD_prop3.G3.residue100', 'feat_CTDD_prop7.G1.residue25', 'feat_CTDD_prop2.G1.residue50', 'feat_CTDD_prop6.G3.residue0', 'feat_CTDD_prop3.G2.residue25', 'feat_CTDD_prop7.G2.residue25', 'feat_CTDD_prop1.G1.residue25', 'feat_CTDT_prop6.Tr1331', 'feat_CTDD_prop7.G1.residue0', 'feat_CTDD_prop1.G2.residue25', 'feat_CTDD_prop4.G2.residue25', 'feat_CTDD_prop4.G1.residue25', 'feat_CTDD_prop7.G2.residue0', 'feat_CTDD_prop7.G1.residue100', 'feat_CTDD_prop1.G1.residue0', 'feat_CTDD_prop3.G3.residue25', 'feat_MolWeight', 'feat_CTDD_prop3.G2.residue0', 'feat_CTDD_prop2.G1.residue75', 'feat_CTDD_prop2.G1.residue25', 'feat_CTDC_hydrophobicity.Group2', 'feat_CTDC_solventaccess.Group2', 'feat_CTDC_hydrophobicity.Group1', 'feat_CTDD_prop3.G3.residue0', 'feat_CTDC_normwaalsvolume.Group1', 'feat_CTDD_prop3.G2.residue100', 'feat_CTDC_polarity.Group2', 'feat_CTDD_prop4.G2.residue0', 'feat_CTDD_prop1.G2.residue0', 'feat_CTDC_polarity.Group3', 'feat_CTDD_prop6.G1.residue25', 'feat_CTDD_prop6.G1.residue100', 'feat_CTDD_prop1.G2.residue100', 'feat_CTDD_prop4.G1.residue0', 'feat_CTDC_normwaalsvolume.Group2', 'feat_CTDC_charge.Group2', 'feat_AAtypes_Small', 'feat_CTDC_hydrophobicity.Group3', 'feat_CTDD_prop2.G1.residue0', 'feat_CTDC_solventaccess.Group3', 'feat_CTDT_prop1.Tr2332', 'feat_CTDC_secondarystruct.Group1', 'feat_CTDT_prop2.Tr1331', 'feat_AAtypes_Charged', 'feat_AAtypes_Polar', 'feat_CTDT_prop5.Tr1221', 'feat_AAtypes_NonPolar', 'feat_CTDC_polarity.Group1', 'feat_CTDD_prop6.G1.residue0', 'feat_CTDC_normwaalsvolume.Group3', 'feat_CTDT_prop3.Tr1221', 'feat_CTDC_polarizability.Group3', 'feat_CTDC_secondarystruct.Group3', 'feat_CTDC_polarizability.Group2', 'feat_CTDD_prop4.G1.residue100', 'feat_CTDD_prop2.G1.residue100', 'feat_CTDC_polarizability.Group1', 'feat_CTDC_secondarystruct.Group2', 'feat_CTDD_prop5.G2.residue50', 'feat_AAtypes_Aliphatic', 'feat_CTDT_prop5.Tr2332', 'feat_CTDT_prop4.Tr1221', 'feat_CTDD_prop5.G2.residue25', 'feat_AAtypes_Tiny', 'feat_CTDD_prop5.G2.residue75', 'feat_CTDT_prop6.Tr1221', 'feat_CTDT_prop2.Tr1221', 'feat_AAtypes_Acidic', 'feat_CTDC_charge.Group3', 'feat_CTDT_prop4.Tr2332', 'feat_CTDT_prop6.Tr2332', 'feat_AAtypes_Basic', 'feat_CTDT_prop7.Tr1221', 'feat_AAC_A', 'feat_AAC_E', 'feat_CTDC_charge.Group1', 'feat_CTDT_prop7.Tr1331', 'feat_CTDT_prop3.Tr1331', 'feat_CTDT_prop2.Tr2332', 'feat_AAC_P', 'feat_AAC_S', 'feat_CTDT_prop1.Tr1331', 'feat_AAC_L', 'feat_AAC_K', 'feat_ScalesGap_scl2.lag2', 'feat_ScalesGap_scl2.1.lag2', 'feat_CTDD_prop5.G2.residue0', 'feat_QSO_Schneider.Xr.K', 'feat_ScalesGap_scl2.lag3', 'feat_CTDT_prop4.Tr1331', 'feat_CTDD_prop5.G2.residue100', 'feat_AAC_T', 'feat_ScalesGap_scl2.1.lag3', 'feat_SOCN_Grantham.lag3', 'feat_ScalesGap_scl1.2.lag2', 'feat_AAC_G', 'feat_AAC_V', 'feat_QSO_Schneider.Xr.S', 'feat_BLOSUM_scl3.2.lag5', 'feat_ScalesGap_scl1.2.lag1', 'feat_QSO_Grantham.Xr.E', 'feat_BLOSUM_scl1.lag5', 'feat_ScalesGap_scl1.5.lag1', 'feat_QSO_Schneider.Xr.L', 'feat_esm2_1258', 'feat_QSO_Schneider.Xr.P', 'feat_QSO_Schneider.Xr.A', 'feat_esm2_1134', 'feat_QSO_Grantham.Xr.A', 'feat_ScalesGap_scl2.lag1', 'feat_esm2_235', 'feat_QSO_Grantham.Xr.L', 'feat_SOCN_Grantham.lag2', 'feat_ScalesGap_scl1.5.lag3', 'feat_ScalesGap_scl5.1.lag2', 'feat_BLOSUM_scl1.lag3', 'feat_esm2_584', 'feat_ScalesGap_scl2.5.lag1', 'feat_esm2_1252', 'feat_AAC_Q', 'feat_ScalesGap_scl2.1.lag1', 'feat_QSO_Grantham.Xr.K', 'feat_BLOSUM_scl2.lag3', 'feat_esm2_92', 'feat_QSO_Schneider.Xr.E']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Configure a RandomForest that handles class imbalance\n",
    "# This is crucial for Boruta's performance\n",
    "rf_fast = RandomForestClassifier(\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced',\n",
    "    max_depth=5,      # A reasonable depth\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Boruta\n",
    "# Boruta will find all features that are statistically more relevant than a random shuffle\n",
    "# We combine a simpler model with a cap on iterations.\n",
    "boruta_selector = BorutaPy(\n",
    "    estimator=rf_fast,\n",
    "    n_estimators='auto', # Let Boruta determine the number of trees\n",
    "    max_iter=10,         # Cap the iterations to 50\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Find support for the tentative features\n",
    "boruta_selector.fit(X_reduced.values, y_resampled.values)\n",
    "\n",
    "# Get the final list of selected features\n",
    "final_features = X_reduced.columns[boruta_selector.support_].tolist()\n",
    "X_final = X_reduced[final_features]\n",
    "\n",
    "print(\"\\nBoruta feature selection complete.\")\n",
    "print(f\"Number of final features: {len(final_features)}\")\n",
    "print(f\"Final feature set shape: {X_final.shape}\")\n",
    "print(\"\\nFinal selected features:\")\n",
    "print(final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97fd8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following data shapes must be consistent for cross-validation:\n",
      "  - Final Features (X_final): (45000, 200)\n",
      "  - Final Target (y_original): (45000,)\n",
      "  - Final Groups (groups):   (45000,)\n",
      "--------------------------------------------------------------------------------\n",
      "--- Starting GroupKFold Cross-Validation ---\n",
      "\n",
      "--- Fold 1/2 ---\n",
      "Balanced Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00     22324\n",
      "           1       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.99     22482\n",
      "   macro avg       0.50      0.50      0.50     22482\n",
      "weighted avg       0.99      0.99      0.99     22482\n",
      "\n",
      "\n",
      "--- Fold 2/2 ---\n",
      "Balanced Accuracy: 0.4998\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00     22344\n",
      "           1       0.00      0.00      0.00       174\n",
      "\n",
      "    accuracy                           0.99     22518\n",
      "   macro avg       0.50      0.50      0.50     22518\n",
      "weighted avg       0.98      0.99      0.99     22518\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Cross-Validation Summary:\n",
      "Mean Balanced Accuracy across all folds: 0.4999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from boruta import BorutaPy\n",
    "\n",
    "\n",
    "\n",
    "y_original = df['Class']\n",
    "groups = df['Info_group']\n",
    "\n",
    "# === STEP 2: APPLY FEATURE SELECTION ===\n",
    "# **CRITICAL FIX:** We filter the ORIGINAL dataframe ('df') using the feature names\n",
    "# you found with Boruta. This guarantees X_final has the same number of rows as y_original.\n",
    "#\n",
    "# This assumes 'final_features' (the list of names) exists from your previous cell.\n",
    "try:\n",
    "    X_final = df[final_features]\n",
    "except NameError:\n",
    "    print(\"FATAL ERROR: 'final_features' list not found. Please run the Boruta cell immediately before this one.\")\n",
    "    exit()\n",
    "\n",
    "# **DEBUGGING CHECK:** These shapes must match.\n",
    "print(\"The following data shapes must be consistent for cross-validation:\")\n",
    "print(f\"  - Final Features (X_final): {X_final.shape}\")\n",
    "print(f\"  - Final Target (y_original): {y_original.shape}\")\n",
    "print(f\"  - Final Groups (groups):   {groups.shape}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# === STEP 3: CREATE AND EVALUATE THE FINAL MODEL PIPELINE ===\n",
    "print(\"--- Starting GroupKFold Cross-Validation ---\")\n",
    "final_model_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',  # Crucial for the imbalanced dataset\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Set up GroupKFold using the two groups in the dataset\n",
    "gkf = GroupKFold(n_splits=2)\n",
    "all_balanced_accuracies = []\n",
    "\n",
    "# Loop through each fold for cross-validation\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X_final, y_original, groups)):\n",
    "    print(f\"\\n--- Fold {i+1}/2 ---\")\n",
    "    \n",
    "    # Split data into training and testing sets for this fold\n",
    "    X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "    y_train, y_test = y_original.iloc[train_index], y_original.iloc[test_index]\n",
    "    \n",
    "    # Train the pipeline\n",
    "    final_model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_model_pipeline.predict(X_test)\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    all_balanced_accuracies.append(balanced_acc)\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "# === STEP 4: FINAL SUMMARY ===\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(f\"Mean Balanced Accuracy across all folds: {np.mean(all_balanced_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba64812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: [-1  1]\n",
      "Labels mapped for XGBoost: [0 1]\n",
      "Using scale_pos_weight for XGBoost: 134.54\n",
      "--------------------------------------------------------------------------------\n",
      "--- Final Model Training: Starting GroupKFold Cross-Validation ---\n",
      "\n",
      "--- Fold 1/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [04:10:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.5410\n",
      "\n",
      "Classification Report (0 = non-epitope, 1 = epitope):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     22324\n",
      "           1       0.65      0.08      0.15       158\n",
      "\n",
      "    accuracy                           0.99     22482\n",
      "   macro avg       0.82      0.54      0.57     22482\n",
      "weighted avg       0.99      0.99      0.99     22482\n",
      "\n",
      "\n",
      "--- Fold 2/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [04:10:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.5592\n",
      "\n",
      "Classification Report (0 = non-epitope, 1 = epitope):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     22344\n",
      "           1       0.28      0.12      0.17       174\n",
      "\n",
      "    accuracy                           0.99     22518\n",
      "   macro avg       0.64      0.56      0.58     22518\n",
      "weighted avg       0.99      0.99      0.99     22518\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Cross-Validation Complete.\n",
      "Mean Balanced Accuracy across all folds: 0.5501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Import the powerful XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- This script assumes 'df' and 'final_feature_names' are already defined ---\n",
    "\n",
    "# 1. Prepare Final Dataset\n",
    "y_original = df['Class']\n",
    "groups = df['Info_group']\n",
    "X_final = df[final_features]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_final = le.fit_transform(y_original)\n",
    "print(f\"Original labels: {y_original.unique()}\")\n",
    "print(f\"Labels mapped for XGBoost: {np.unique(y_final)}\")\n",
    "\n",
    "# Calculate scale_pos_weight for XGBoost's imbalanced data handling\n",
    "# This should be the ratio of negative samples (now 0) to positive samples (1)\n",
    "neg_count = np.sum(y_final == 0)\n",
    "pos_count = np.sum(y_final == 1)\n",
    "scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1\n",
    "print(f\"Using scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# === STEP 4: TRAIN AND EVALUATE FINAL XGBOOST MODEL ===\n",
    "print(\"--- Final Model Training: Starting GroupKFold Cross-Validation ---\")\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "gkf = GroupKFold(n_splits=2)\n",
    "all_balanced_accuracies = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X_final, y_final, groups)):\n",
    "    print(f\"\\n--- Fold {i+1}/2 ---\")\n",
    "    X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "    y_train, y_test = y_final[train_index], y_final[test_index]\n",
    "\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    all_balanced_accuracies.append(balanced_acc)\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "    print(\"Classification Report (0 = non-epitope, 1 = epitope):\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# === STEP 5: FINAL SUMMARY ===\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCross-Validation Complete.\")\n",
    "print(f\"Mean Balanced Accuracy across all folds: {np.mean(all_balanced_accuracies):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05aad588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Hyperparameter Tuning with RandomizedSearchCV ---\n",
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:02:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Complete ---\n",
      "Best Balanced Accuracy Score Found: 0.6710\n",
      "\n",
      "Best Parameters Found:\n",
      "{'xgb__subsample': 0.8, 'xgb__n_estimators': 300, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.01, 'xgb__colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- This script assumes 'df' and 'final_feature_names' are already defined ---\n",
    "\n",
    "# 1. Prepare Data\n",
    "y_original = df['Class']\n",
    "groups = df['Info_group']\n",
    "X_final = df[final_features]\n",
    "\n",
    "# Map labels from {-1, 1} to {0, 1} for XGBoost\n",
    "le = LabelEncoder()\n",
    "y_final = le.fit_transform(y_original)\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_pos_weight = np.sum(y_final == 0) / np.sum(y_final == 1)\n",
    "\n",
    "# 2. Define the Hyperparameter Search Space\n",
    "# We are creating a 'dictionary' of parameters to test.\n",
    "param_dist = {\n",
    "    'xgb__n_estimators': [100, 200, 300],\n",
    "    'xgb__max_depth': [3, 4, 5, 6],\n",
    "    'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'xgb__subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'xgb__colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# 3. Create the XGBoost Pipeline\n",
    "# The 'xgb__' prefix is used to tell the pipeline which component to apply the parameters to.\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Set up Randomized Search with GroupKFold\n",
    "# We use GroupKFold for the outer loop to respect the data dependencies.\n",
    "gkf = GroupKFold(n_splits=2)\n",
    "\n",
    "# We will optimize for balanced_accuracy\n",
    "scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# n_iter=20 will test 20 random combinations from your param_dist.\n",
    "# This is a good starting point for a balance of search time and thoroughness.\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=scorer,\n",
    "    cv=gkf,  # Use GroupKFold for the inner cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"--- Starting Hyperparameter Tuning with RandomizedSearchCV ---\")\n",
    "# Fit the search on your full dataset\n",
    "random_search.fit(X_final, y_final, groups=groups)\n",
    "\n",
    "# 5. Show the Best Results\n",
    "print(\"\\n--- Tuning Complete ---\")\n",
    "print(f\"Best Balanced Accuracy Score Found: {random_search.best_score_:.4f}\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc23833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and prepared.\n",
      "--------------------------------------------------------------------------------\n",
      "--- Starting Hyperparameter Tuning ---\n",
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:27:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Complete ---\n",
      "Best Balanced Accuracy Score Found: 0.6751\n",
      "\n",
      "Best Parameters Found:\n",
      "{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Evaluating Best Model with ADASYN and Optimal Threshold ---\n",
      "\n",
      "--- Fold 1/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:27:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold for this fold: 0.5684\n",
      "\n",
      "Final Classification Report (with optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     22324\n",
      "           1       0.15      0.08      0.11       158\n",
      "\n",
      "    accuracy                           0.99     22482\n",
      "   macro avg       0.57      0.54      0.55     22482\n",
      "weighted avg       0.99      0.99      0.99     22482\n",
      "\n",
      "\n",
      "--- Fold 2/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garvit\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [05:27:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold for this fold: 0.7874\n",
      "\n",
      "Final Classification Report (with optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     22344\n",
      "           1       0.19      0.10      0.13       174\n",
      "\n",
      "    accuracy                           0.99     22518\n",
      "   macro avg       0.59      0.55      0.56     22518\n",
      "weighted avg       0.99      0.99      0.99     22518\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Final Model Performance Summary:\n",
      "Mean Balanced Accuracy (with optimal threshold): 0.5448\n",
      "Mean F1-Score for Positive Class (with optimal threshold): 0.1204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, make_scorer, precision_recall_curve, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "# We need the imblearn pipeline for the FINAL evaluation step\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# --- STEP 1: LOAD AND PREPARE DATA ---\n",
    "\n",
    "y_original = df['Class']\n",
    "groups = df['Info_group']\n",
    "X_final = df[final_features]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_final = le.fit_transform(y_original)\n",
    "print(\"Data loaded and prepared.\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# --- STEP 2: HYPERPARAMETER TUNING (WITHOUT ADASYN IN PIPELINE) ---\n",
    "print(\"--- Starting Hyperparameter Tuning ---\")\n",
    "# Define the search space\n",
    "param_dist = {\n",
    "    'xgb__n_estimators': [100, 200, 300],\n",
    "    'xgb__max_depth': [3, 4, 5, 6],\n",
    "    'xgb__learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Calculate scale_pos_weight for XGBoost to handle imbalance during the search\n",
    "scale_pos_weight = np.sum(y_final == 0) / np.sum(y_final == 1)\n",
    "\n",
    "# Create a pipeline *without* the ADASYN step for the search\n",
    "search_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight, # Handle imbalance this way for the search\n",
    "        random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Set up the search\n",
    "gkf = GroupKFold(n_splits=2)\n",
    "scorer = make_scorer(balanced_accuracy_score)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=search_pipeline, param_distributions=param_dist,\n",
    "    n_iter=15, scoring=scorer, cv=gkf, verbose=1, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run the search to find the best parameters\n",
    "random_search.fit(X_final, y_final, groups=groups)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\n--- Tuning Complete ---\")\n",
    "print(f\"Best Balanced Accuracy Score Found: {random_search.best_score_:.4f}\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "# We need to strip the 'xgb__' prefix for the next step\n",
    "final_params = {key.replace('xgb__', ''): value for key, value in best_params.items()}\n",
    "print(final_params)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# --- STEP 3: EVALUATE THE FINAL MODEL (WITH ADASYN AND BEST PARAMS) ---\n",
    "print(\"\\n--- Evaluating Best Model with ADASYN and Optimal Threshold ---\")\n",
    "# Create the final pipeline using the imblearn pipeline and the best parameters found\n",
    "final_pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    # Pass the best parameters to the final classifier\n",
    "    ('xgb', XGBClassifier(\n",
    "        random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss', **final_params\n",
    "    ))\n",
    "])\n",
    "\n",
    "all_f1_scores = []\n",
    "all_balanced_accuracies = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X_final, y_final, groups)):\n",
    "    print(f\"\\n--- Fold {i+1}/2 ---\")\n",
    "    X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "    y_train, y_test = y_final[train_index], y_final[test_index]\n",
    "\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "    y_pred_probs = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    print(f\"Optimal Threshold for this fold: {best_threshold:.4f}\")\n",
    "\n",
    "    y_pred_final = (y_pred_probs >= best_threshold).astype(int)\n",
    "    all_f1_scores.append(f1_score(y_test, y_pred_final))\n",
    "    all_balanced_accuracies.append(balanced_accuracy_score(y_test, y_pred_final))\n",
    "\n",
    "    print(\"\\nFinal Classification Report (with optimal threshold):\")\n",
    "    print(classification_report(y_test, y_pred_final, zero_division=0))\n",
    "\n",
    "# --- 4. FINAL SUMMARY ---\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFinal Model Performance Summary:\")\n",
    "print(f\"Mean Balanced Accuracy (with optimal threshold): {np.mean(all_balanced_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score for Positive Class (with optimal threshold): {np.mean(all_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff5ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yping-extensions (c:\\users\\garvit\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/5c/5e/068798a8c7087863e7772e9363a880ab13fe55a5a7ede8ec42fab8a1acbb/optuna-4.4.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/54/7e/ac0991d1745f7d755fc1cd381b3990a45b404b4d008fc75e2a983516fbfe/alembic-1.14.1-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/e3/51/9b208e85196941db2f0654ad0357ca6388ab3ed67efdbfc799f35d1f83aa/colorlog-6.9.0-py3-none-any.whl.metadata\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from optuna) (1.4.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from optuna) (4.59.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/87/fb/99f81ac72ae23375f22b7afdb7642aba97c00a713c217124420147681a2f/mako-1.3.10-py3-none-any.whl.metadata\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (7.0.1)\n",
      "Collecting importlib-resources (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\garvit\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 395.9/395.9 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 233.6/233.6 kB ? eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Installing collected packages: Mako, importlib-resources, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.14.1 colorlog-6.9.0 importlib-resources-6.4.5 optuna-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90d1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 05:31:18,013] A new study created in memory with name: no-name-74765366-3076-4407-a683-2b0f96e74d85\n",
      "[I 2025-07-25 05:31:28,552] Trial 0 finished with value: 0.5380547573707262 and parameters: {'n_estimators': 135, 'max_depth': 5, 'learning_rate': 0.03810057823702595, 'subsample': 0.7392725134542437, 'colsample_bytree': 0.948235552743249}. Best is trial 0 with value: 0.5380547573707262.\n",
      "[I 2025-07-25 05:31:44,593] Trial 1 finished with value: 0.547530209562233 and parameters: {'n_estimators': 174, 'max_depth': 6, 'learning_rate': 0.018405397085269885, 'subsample': 0.7490465955148484, 'colsample_bytree': 0.9293129436100824}. Best is trial 1 with value: 0.547530209562233.\n",
      "[I 2025-07-25 05:32:02,526] Trial 2 finished with value: 0.5292393667289721 and parameters: {'n_estimators': 242, 'max_depth': 5, 'learning_rate': 0.0758085580675238, 'subsample': 0.8682079921265471, 'colsample_bytree': 0.9076715980492622}. Best is trial 1 with value: 0.547530209562233.\n",
      "[I 2025-07-25 05:32:12,626] Trial 3 finished with value: 0.5276794856677767 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.09960959716883067, 'subsample': 0.974933204436675, 'colsample_bytree': 0.6855313750663559}. Best is trial 1 with value: 0.547530209562233.\n",
      "[I 2025-07-25 05:32:48,014] Trial 4 finished with value: 0.5289595817191541 and parameters: {'n_estimators': 374, 'max_depth': 6, 'learning_rate': 0.031099334521244314, 'subsample': 0.8523279567058407, 'colsample_bytree': 0.7167560201229536}. Best is trial 1 with value: 0.547530209562233.\n",
      "[I 2025-07-25 05:33:00,064] Trial 5 finished with value: 0.5386590165821201 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.039138253664960425, 'subsample': 0.7556718684093958, 'colsample_bytree': 0.8612853735078163}. Best is trial 1 with value: 0.547530209562233.\n",
      "[I 2025-07-25 05:33:12,681] Trial 6 finished with value: 0.5668864936653282 and parameters: {'n_estimators': 268, 'max_depth': 4, 'learning_rate': 0.006962392464256556, 'subsample': 0.6822231159784347, 'colsample_bytree': 0.8330847632726134}. Best is trial 6 with value: 0.5668864936653282.\n",
      "[I 2025-07-25 05:33:20,334] Trial 7 finished with value: 0.5576144785118443 and parameters: {'n_estimators': 134, 'max_depth': 5, 'learning_rate': 0.007543304609317887, 'subsample': 0.8200450768437542, 'colsample_bytree': 0.8310609156658417}. Best is trial 6 with value: 0.5668864936653282.\n",
      "[I 2025-07-25 05:33:36,588] Trial 8 finished with value: 0.5331021340448061 and parameters: {'n_estimators': 314, 'max_depth': 5, 'learning_rate': 0.024633438045032825, 'subsample': 0.7703687936985052, 'colsample_bytree': 0.7596086871088937}. Best is trial 6 with value: 0.5668864936653282.\n",
      "[I 2025-07-25 05:33:50,037] Trial 9 finished with value: 0.5438049065114665 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.006033015591696371, 'subsample': 0.8168149092895663, 'colsample_bytree': 0.7866140958873709}. Best is trial 6 with value: 0.5668864936653282.\n",
      "[I 2025-07-25 05:34:00,176] Trial 10 finished with value: 0.5715292764771147 and parameters: {'n_estimators': 291, 'max_depth': 3, 'learning_rate': 0.011390706010588586, 'subsample': 0.6038858921083186, 'colsample_bytree': 0.6050082853155732}. Best is trial 10 with value: 0.5715292764771147.\n",
      "[I 2025-07-25 05:34:11,530] Trial 11 finished with value: 0.5721824290621282 and parameters: {'n_estimators': 290, 'max_depth': 3, 'learning_rate': 0.010824871702236791, 'subsample': 0.6051814519169486, 'colsample_bytree': 0.6300942037643753}. Best is trial 11 with value: 0.5721824290621282.\n",
      "[I 2025-07-25 05:34:22,810] Trial 12 finished with value: 0.5704380089756611 and parameters: {'n_estimators': 338, 'max_depth': 3, 'learning_rate': 0.013514456071891102, 'subsample': 0.6073479861794446, 'colsample_bytree': 0.611907772924815}. Best is trial 11 with value: 0.5721824290621282.\n",
      "[I 2025-07-25 05:34:32,761] Trial 13 finished with value: 0.5723952909073868 and parameters: {'n_estimators': 275, 'max_depth': 3, 'learning_rate': 0.011595163638625804, 'subsample': 0.6631650844291274, 'colsample_bytree': 0.6050986611928613}. Best is trial 13 with value: 0.5723952909073868.\n",
      "[I 2025-07-25 05:34:42,759] Trial 14 finished with value: 0.5609145351614966 and parameters: {'n_estimators': 221, 'max_depth': 4, 'learning_rate': 0.011179702061630634, 'subsample': 0.666543906524568, 'colsample_bytree': 0.6654114657546003}. Best is trial 13 with value: 0.5723952909073868.\n",
      "[I 2025-07-25 05:34:54,858] Trial 15 finished with value: 0.5558264512293768 and parameters: {'n_estimators': 388, 'max_depth': 3, 'learning_rate': 0.016740894897214028, 'subsample': 0.676559823526844, 'colsample_bytree': 0.6539035461571401}. Best is trial 13 with value: 0.5723952909073868.\n",
      "[I 2025-07-25 05:35:09,131] Trial 16 finished with value: 0.5573053946133051 and parameters: {'n_estimators': 338, 'max_depth': 4, 'learning_rate': 0.009070706079766259, 'subsample': 0.645629000957932, 'colsample_bytree': 0.7241341226869815}. Best is trial 13 with value: 0.5723952909073868.\n",
      "[I 2025-07-25 05:35:27,195] Trial 17 finished with value: 0.5400958298136604 and parameters: {'n_estimators': 269, 'max_depth': 7, 'learning_rate': 0.014450603838898115, 'subsample': 0.7058082403245866, 'colsample_bytree': 0.6365917047361791}. Best is trial 13 with value: 0.5723952909073868.\n",
      "[I 2025-07-25 05:35:35,789] Trial 18 finished with value: 0.5830049473793607 and parameters: {'n_estimators': 223, 'max_depth': 3, 'learning_rate': 0.005568913216455537, 'subsample': 0.6341009153688854, 'colsample_bytree': 0.9942594098919586}. Best is trial 18 with value: 0.5830049473793607.\n",
      "[I 2025-07-25 05:35:45,480] Trial 19 finished with value: 0.5679674272484165 and parameters: {'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.0053130519699837436, 'subsample': 0.9332528385468541, 'colsample_bytree': 0.9737662466810846}. Best is trial 18 with value: 0.5830049473793607.\n",
      "[I 2025-07-25 05:35:54,034] Trial 20 finished with value: 0.5701284891180719 and parameters: {'n_estimators': 236, 'max_depth': 3, 'learning_rate': 0.00859706983827393, 'subsample': 0.7142581934081365, 'colsample_bytree': 0.8829376342139778}. Best is trial 18 with value: 0.5830049473793607.\n",
      "[I 2025-07-25 05:36:05,300] Trial 21 finished with value: 0.5723098175023633 and parameters: {'n_estimators': 296, 'max_depth': 3, 'learning_rate': 0.009849337573136793, 'subsample': 0.6338033272292947, 'colsample_bytree': 0.7190604538646173}. Best is trial 18 with value: 0.5830049473793607.\n",
      "[I 2025-07-25 05:36:14,150] Trial 22 finished with value: 0.5941917669056735 and parameters: {'n_estimators': 259, 'max_depth': 3, 'learning_rate': 0.005851955500344209, 'subsample': 0.6451199728572943, 'colsample_bytree': 0.7455237358299013}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:36:22,744] Trial 23 finished with value: 0.5683613510672518 and parameters: {'n_estimators': 170, 'max_depth': 4, 'learning_rate': 0.005656795362620531, 'subsample': 0.7072626712932846, 'colsample_bytree': 0.9985525132852281}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:36:32,095] Trial 24 finished with value: 0.5931056123314324 and parameters: {'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.005158221854855732, 'subsample': 0.6485507534010251, 'colsample_bytree': 0.7694066234606342}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:36:43,214] Trial 25 finished with value: 0.5684239672827984 and parameters: {'n_estimators': 251, 'max_depth': 4, 'learning_rate': 0.006938283119235013, 'subsample': 0.6409411019097034, 'colsample_bytree': 0.7677641785819985}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:36:52,844] Trial 26 finished with value: 0.586878600356403 and parameters: {'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.0051015792609199395, 'subsample': 0.6325123702541666, 'colsample_bytree': 0.8110580317400116}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:37:02,454] Trial 27 finished with value: 0.5645231809005418 and parameters: {'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.005191030977250323, 'subsample': 0.7902938270102855, 'colsample_bytree': 0.8148339326101279}. Best is trial 22 with value: 0.5941917669056735.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 05:37:13,080] Trial 28 finished with value: 0.5796635244813589 and parameters: {'n_estimators': 255, 'max_depth': 3, 'learning_rate': 0.006787201032529856, 'subsample': 0.7238016993088291, 'colsample_bytree': 0.7498518819687944}. Best is trial 22 with value: 0.5941917669056735.\n",
      "[I 2025-07-25 05:37:34,494] Trial 29 finished with value: 0.5308887973738049 and parameters: {'n_estimators': 319, 'max_depth': 7, 'learning_rate': 0.048662413774042755, 'subsample': 0.6891544368526749, 'colsample_bytree': 0.7940961127742785}. Best is trial 22 with value: 0.5941917669056735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Tuning Complete ---\n",
      "Best Balanced Accuracy Score Found: 0.5942\n",
      "\n",
      "Best Parameters Found:\n",
      "{'n_estimators': 259, 'max_depth': 3, 'learning_rate': 0.005851955500344209, 'subsample': 0.6451199728572943, 'colsample_bytree': 0.7455237358299013}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# --- This code replaces your RandomizedSearchCV block ---\n",
    "\n",
    "# 1. Define the objective function for Optuna to optimize\n",
    "def objective(trial):\n",
    "    # Define the search space within the function\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "\n",
    "    # Create the full pipeline with ADASYN and XGBoost\n",
    "    pipeline = ImbPipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('adasyn', ADASYN(random_state=42)),\n",
    "        ('xgb', XGBClassifier(random_state=42, n_jobs=-1, **params))\n",
    "    ])\n",
    "\n",
    "    # Manual cross-validation loop\n",
    "    scores = []\n",
    "    gkf = GroupKFold(n_splits=2)\n",
    "    for train_index, test_index in gkf.split(X_final, y_final, groups=groups):\n",
    "        X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "        y_train, y_test = y_final[train_index], y_final[test_index]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        scores.append(balanced_accuracy_score(y_test, preds))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "# n_trials=30 will test 30 intelligent combinations.\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 3. Print the best results\n",
    "print(\"\\n--- Optuna Tuning Complete ---\")\n",
    "print(f\"Best Balanced Accuracy Score Found: {study.best_value:.4f}\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "300fc829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 06:08:25,562] A new study created in memory with name: no-name-44e348cc-5cc9-40ca-8107-0887a299def5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Optuna Tuning (Objective: Maximize F1-Score with Regularization) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 06:08:38,092] Trial 0 finished with value: 0.1838476508201279 and parameters: {'n_estimators': 594, 'max_depth': 5, 'learning_rate': 0.0053908191963710494, 'subsample': 0.6795996525372607, 'colsample_bytree': 0.6359233229739005, 'gamma': 5.958085789695352, 'lambda': 7.5912783302446805, 'alpha': 0.5269557196196872}. Best is trial 0 with value: 0.1838476508201279.\n",
      "[I 2025-07-25 06:08:43,426] Trial 1 finished with value: 0.16177227635037914 and parameters: {'n_estimators': 402, 'max_depth': 3, 'learning_rate': 0.01715722372627544, 'subsample': 0.6254044836750902, 'colsample_bytree': 0.9250546349188973, 'gamma': 0.8758975212434361, 'lambda': 6.07119625115786, 'alpha': 1.7517794860028668}. Best is trial 0 with value: 0.1838476508201279.\n",
      "[I 2025-07-25 06:09:01,029] Trial 2 finished with value: 0.20262783677914226 and parameters: {'n_estimators': 595, 'max_depth': 6, 'learning_rate': 0.005418989963775516, 'subsample': 0.9410509192713203, 'colsample_bytree': 0.9042745660321894, 'gamma': 1.6691759543394635, 'lambda': 2.416268521119, 'alpha': 4.491333880433989}. Best is trial 2 with value: 0.20262783677914226.\n",
      "[I 2025-07-25 06:09:10,905] Trial 3 finished with value: 0.2934369009813178 and parameters: {'n_estimators': 281, 'max_depth': 7, 'learning_rate': 0.02039395818849903, 'subsample': 0.6079377031459849, 'colsample_bytree': 0.9637770374873185, 'gamma': 1.9968012687227177, 'lambda': 1.3068635976810812, 'alpha': 4.684610734674191}. Best is trial 3 with value: 0.2934369009813178.\n",
      "[I 2025-07-25 06:09:19,165] Trial 4 finished with value: 0.3480590486604702 and parameters: {'n_estimators': 342, 'max_depth': 5, 'learning_rate': 0.037245052359173615, 'subsample': 0.8780005941128182, 'colsample_bytree': 0.660961275621842, 'gamma': 1.2339994525039033, 'lambda': 2.7289163366066256, 'alpha': 1.5325618848808487}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:25,647] Trial 5 finished with value: 0.19077788495343867 and parameters: {'n_estimators': 425, 'max_depth': 3, 'learning_rate': 0.0217612968005344, 'subsample': 0.6206579730417158, 'colsample_bytree': 0.8878052529823559, 'gamma': 6.292818266561256, 'lambda': 1.6559454360927646, 'alpha': 3.1153586787166927}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:29,208] Trial 6 finished with value: 0.22588975782379078 and parameters: {'n_estimators': 202, 'max_depth': 4, 'learning_rate': 0.03330500144399423, 'subsample': 0.9176573273514955, 'colsample_bytree': 0.7188831464346482, 'gamma': 7.045841618171451, 'lambda': 1.8172448761726094, 'alpha': 3.2914185958256885}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:35,265] Trial 7 finished with value: 0.2643701095250678 and parameters: {'n_estimators': 434, 'max_depth': 3, 'learning_rate': 0.04511092845577466, 'subsample': 0.6674701012628079, 'colsample_bytree': 0.6527934037489759, 'gamma': 7.450637175188746, 'lambda': 1.2067410595385715, 'alpha': 2.2949407316674297}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:42,988] Trial 8 finished with value: 0.3314172898175973 and parameters: {'n_estimators': 369, 'max_depth': 6, 'learning_rate': 0.029636609129724625, 'subsample': 0.7236859373690308, 'colsample_bytree': 0.6584286583062146, 'gamma': 7.995814668520806, 'lambda': 5.923806458164992, 'alpha': 1.3337593982693492}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:47,167] Trial 9 finished with value: 0.10684425379319923 and parameters: {'n_estimators': 233, 'max_depth': 3, 'learning_rate': 0.016468419858841676, 'subsample': 0.6720400678033551, 'colsample_bytree': 0.9796789144031036, 'gamma': 1.150513835867063, 'lambda': 9.627622721806985, 'alpha': 3.76680818171176}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:09:54,896] Trial 10 finished with value: 0.1772524611214153 and parameters: {'n_estimators': 323, 'max_depth': 5, 'learning_rate': 0.009873625471328662, 'subsample': 0.8445644908294753, 'colsample_bytree': 0.7790220875735344, 'gamma': 4.016254512881249, 'lambda': 3.8280341189886973, 'alpha': 0.16238228882453365}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:01,770] Trial 11 finished with value: 0.3218046385644151 and parameters: {'n_estimators': 346, 'max_depth': 6, 'learning_rate': 0.030752584996279593, 'subsample': 0.7787621382731834, 'colsample_bytree': 0.7095072118172326, 'gamma': 9.755513099642123, 'lambda': 3.747988194788024, 'alpha': 1.2830416929138455}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:09,295] Trial 12 finished with value: 0.3422252621979024 and parameters: {'n_estimators': 488, 'max_depth': 6, 'learning_rate': 0.049688053254008296, 'subsample': 0.7896082690960622, 'colsample_bytree': 0.6989577419284199, 'gamma': 3.726314983533708, 'lambda': 5.584834641272991, 'alpha': 1.1490215096169494}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:17,511] Trial 13 finished with value: 0.2957864747338432 and parameters: {'n_estimators': 495, 'max_depth': 7, 'learning_rate': 0.04572333039099464, 'subsample': 0.8486391083923737, 'colsample_bytree': 0.6002425035219017, 'gamma': 3.5809053670991142, 'lambda': 2.758007520608518, 'alpha': 0.9279874418702634}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:24,493] Trial 14 finished with value: 0.31931637519872813 and parameters: {'n_estimators': 501, 'max_depth': 4, 'learning_rate': 0.049980498424642396, 'subsample': 0.9930343386167486, 'colsample_bytree': 0.8028953747903074, 'gamma': 3.160757672244516, 'lambda': 5.092990621044493, 'alpha': 2.1674625054852275}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:33,661] Trial 15 finished with value: 0.3449782994070542 and parameters: {'n_estimators': 490, 'max_depth': 5, 'learning_rate': 0.03584551609242035, 'subsample': 0.7823307832091407, 'colsample_bytree': 0.7314369549582406, 'gamma': 4.648288191543182, 'lambda': 4.32679341995961, 'alpha': 1.6628701034826525}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:39,041] Trial 16 finished with value: 0.12674489077610512 and parameters: {'n_estimators': 288, 'max_depth': 4, 'learning_rate': 0.009021048711419507, 'subsample': 0.8578235510066977, 'colsample_bytree': 0.7712769799223033, 'gamma': 5.152956866347452, 'lambda': 2.1962220762665594, 'alpha': 2.6889647932007357}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:51,454] Trial 17 finished with value: 0.2652014652014652 and parameters: {'n_estimators': 531, 'max_depth': 5, 'learning_rate': 0.011504450399209146, 'subsample': 0.8975936971299637, 'colsample_bytree': 0.8443873383036498, 'gamma': 2.4774340933216745, 'lambda': 3.558909894528059, 'alpha': 1.9730952939814705}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:10:59,891] Trial 18 finished with value: 0.284006084006084 and parameters: {'n_estimators': 454, 'max_depth': 4, 'learning_rate': 0.02398907525747074, 'subsample': 0.7438444912374598, 'colsample_bytree': 0.7441296180760613, 'gamma': 0.23637070566231466, 'lambda': 4.34444570328114, 'alpha': 1.731034709368362}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:11:07,416] Trial 19 finished with value: 0.33485890101437427 and parameters: {'n_estimators': 552, 'max_depth': 5, 'learning_rate': 0.036858820566874034, 'subsample': 0.7479299480214988, 'colsample_bytree': 0.6783612274162554, 'gamma': 4.721793327808171, 'lambda': 2.9621895848343915, 'alpha': 2.690116823551352}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:11:17,495] Trial 20 finished with value: 0.27400051677158693 and parameters: {'n_estimators': 385, 'max_depth': 6, 'learning_rate': 0.013094007550417069, 'subsample': 0.8185429714713949, 'colsample_bytree': 0.6025057159586847, 'gamma': 8.87582836482871, 'lambda': 1.9756010803905568, 'alpha': 0.7197330408432727}. Best is trial 4 with value: 0.3480590486604702.\n",
      "[I 2025-07-25 06:11:26,895] Trial 21 finished with value: 0.323011323011323 and parameters: {'n_estimators': 468, 'max_depth': 6, 'learning_rate': 0.03938777764603822, 'subsample': 0.7815711387171349, 'colsample_bytree': 0.7033586697239025, 'gamma': 2.7484560156633124, 'lambda': 4.6882642860780415, 'alpha': 1.2852877908943245}. Best is trial 4 with value: 0.3480590486604702.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 06:11:40,963] Trial 22 finished with value: 0.34950852308075153 and parameters: {'n_estimators': 527, 'max_depth': 5, 'learning_rate': 0.026927421596894395, 'subsample': 0.8110962615041424, 'colsample_bytree': 0.7400427642068348, 'gamma': 4.650000029801672, 'lambda': 6.739325059309178, 'alpha': 0.15170643152379637}. Best is trial 22 with value: 0.34950852308075153.\n",
      "[I 2025-07-25 06:11:55,442] Trial 23 finished with value: 0.3496412666996537 and parameters: {'n_estimators': 539, 'max_depth': 5, 'learning_rate': 0.026945190432002563, 'subsample': 0.879409084237547, 'colsample_bytree': 0.7518408744918611, 'gamma': 5.003324264417698, 'lambda': 7.093218520829722, 'alpha': 0.15195263119493796}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:12:08,312] Trial 24 finished with value: 0.34565064605071094 and parameters: {'n_estimators': 552, 'max_depth': 5, 'learning_rate': 0.025986401499396596, 'subsample': 0.8896261477114624, 'colsample_bytree': 0.8158342007112201, 'gamma': 5.955085886469246, 'lambda': 8.548244738679676, 'alpha': 0.12394246529945241}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:12:21,731] Trial 25 finished with value: 0.3287326278209869 and parameters: {'n_estimators': 557, 'max_depth': 4, 'learning_rate': 0.027170712844767995, 'subsample': 0.9744196419476792, 'colsample_bytree': 0.7486365411321112, 'gamma': 0.09990353211383773, 'lambda': 7.347573578954144, 'alpha': 0.4624231740433442}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:12:31,330] Trial 26 finished with value: 0.2454776219104876 and parameters: {'n_estimators': 302, 'max_depth': 5, 'learning_rate': 0.017702746830518593, 'subsample': 0.8743184301654253, 'colsample_bytree': 0.8452079882713357, 'gamma': 5.1098716952558165, 'lambda': 6.8279822307992575, 'alpha': 0.26427530688612233}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:12:44,226] Trial 27 finished with value: 0.3302734764404865 and parameters: {'n_estimators': 523, 'max_depth': 5, 'learning_rate': 0.019921267913088094, 'subsample': 0.8194491970174709, 'colsample_bytree': 0.6796543523671341, 'gamma': 6.551710495132566, 'lambda': 9.43028227980551, 'alpha': 0.022112456745716935}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:12:52,043] Trial 28 finished with value: 0.31006006006006004 and parameters: {'n_estimators': 353, 'max_depth': 4, 'learning_rate': 0.040091384540250206, 'subsample': 0.940910875807362, 'colsample_bytree': 0.7745966518958816, 'gamma': 4.282807368135921, 'lambda': 2.4599456369332167, 'alpha': 0.7752152716455374}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:13:05,041] Trial 29 finished with value: 0.3042359938911663 and parameters: {'n_estimators': 581, 'max_depth': 5, 'learning_rate': 0.013981769168060107, 'subsample': 0.8184054367423199, 'colsample_bytree': 0.6287883205361233, 'gamma': 5.410181805229815, 'lambda': 7.529609756781269, 'alpha': 0.5270582656325316}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:13:15,753] Trial 30 finished with value: 0.3234676438829041 and parameters: {'n_estimators': 409, 'max_depth': 6, 'learning_rate': 0.024286307475619745, 'subsample': 0.9202872945026873, 'colsample_bytree': 0.8352531698312857, 'gamma': 8.311628579906817, 'lambda': 3.3522713016951964, 'alpha': 0.9844136528149354}. Best is trial 23 with value: 0.3496412666996537.\n",
      "[I 2025-07-25 06:13:26,754] Trial 31 finished with value: 0.3579754020813623 and parameters: {'n_estimators': 546, 'max_depth': 5, 'learning_rate': 0.02509043662632323, 'subsample': 0.8819035050967043, 'colsample_bytree': 0.8168270289163001, 'gamma': 5.6397345557151395, 'lambda': 8.567438858981605, 'alpha': 0.471326008635036}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:13:35,943] Trial 32 finished with value: 0.34889586086535457 and parameters: {'n_estimators': 525, 'max_depth': 5, 'learning_rate': 0.030040478052984217, 'subsample': 0.8715673974318009, 'colsample_bytree': 0.7594317097505985, 'gamma': 5.509134067253167, 'lambda': 6.636653921433952, 'alpha': 0.5950570027247969}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:13:47,083] Trial 33 finished with value: 0.34212454212454213 and parameters: {'n_estimators': 579, 'max_depth': 5, 'learning_rate': 0.03220172558057502, 'subsample': 0.8393980135579261, 'colsample_bytree': 0.8659266763725354, 'gamma': 5.862186514493395, 'lambda': 6.655831051902844, 'alpha': 0.5163582463032375}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:13:59,838] Trial 34 finished with value: 0.3274002026342452 and parameters: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.02864995407673139, 'subsample': 0.9181482778583259, 'colsample_bytree': 0.7877285443600498, 'gamma': 5.604240149987144, 'lambda': 8.652325267349179, 'alpha': 0.3775824048452821}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:14:13,136] Trial 35 finished with value: 0.3300190913852236 and parameters: {'n_estimators': 527, 'max_depth': 5, 'learning_rate': 0.018890553369436305, 'subsample': 0.862980083160388, 'colsample_bytree': 0.7546741552816044, 'gamma': 6.468913343362886, 'lambda': 8.232916267027907, 'alpha': 0.010765616133748573}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:14:23,859] Trial 36 finished with value: 0.33634565447676545 and parameters: {'n_estimators': 514, 'max_depth': 6, 'learning_rate': 0.02157544071839594, 'subsample': 0.8964754360227218, 'colsample_bytree': 0.8121893705104763, 'gamma': 6.987980205949059, 'lambda': 6.535630445488508, 'alpha': 0.7033894447043522}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:14:46,946] Trial 37 finished with value: 0.20585823694631986 and parameters: {'n_estimators': 564, 'max_depth': 7, 'learning_rate': 0.005046703985183808, 'subsample': 0.9447674261078396, 'colsample_bytree': 0.9461736551950517, 'gamma': 4.323122762319428, 'lambda': 5.253286447194615, 'alpha': 1.0302665969572071}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:14:56,210] Trial 38 finished with value: 0.13512903635618992 and parameters: {'n_estimators': 464, 'max_depth': 4, 'learning_rate': 0.006760581765307609, 'subsample': 0.823994890648784, 'colsample_bytree': 0.8867683619804334, 'gamma': 3.3523054968301147, 'lambda': 7.948798740596157, 'alpha': 0.6499598832833406}. Best is trial 31 with value: 0.3579754020813623.\n",
      "[I 2025-07-25 06:15:07,484] Trial 39 finished with value: 0.32789373166905394 and parameters: {'n_estimators': 541, 'max_depth': 5, 'learning_rate': 0.02335802358745227, 'subsample': 0.8758925556865658, 'colsample_bytree': 0.7580458605946961, 'gamma': 4.769868595629194, 'lambda': 6.332999741524912, 'alpha': 4.97380937596873}. Best is trial 31 with value: 0.3579754020813623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Tuning Complete ---\n",
      "Best F1-Score Found: 0.3580\n",
      "\n",
      "Best Parameters Found:\n",
      "{'n_estimators': 546, 'max_depth': 5, 'learning_rate': 0.02509043662632323, 'subsample': 0.8819035050967043, 'colsample_bytree': 0.8168270289163001, 'gamma': 5.6397345557151395, 'lambda': 8.567438858981605, 'alpha': 0.471326008635036}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Evaluating Best Regularized Model with Optimal Threshold ---\n",
      "\n",
      "--- Fold 1/2 ---\n",
      "Optimal Threshold for this fold: 0.7252\n",
      "\n",
      "Final Classification Report (with optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22324\n",
      "           1       0.70      0.46      0.56       158\n",
      "\n",
      "    accuracy                           0.99     22482\n",
      "   macro avg       0.85      0.73      0.78     22482\n",
      "weighted avg       0.99      0.99      0.99     22482\n",
      "\n",
      "\n",
      "--- Fold 2/2 ---\n",
      "Optimal Threshold for this fold: 0.5559\n",
      "\n",
      "Final Classification Report (with optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     22344\n",
      "           1       0.25      0.15      0.19       174\n",
      "\n",
      "    accuracy                           0.99     22518\n",
      "   macro avg       0.62      0.57      0.59     22518\n",
      "weighted avg       0.99      0.99      0.99     22518\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Final Model Performance Summary:\n",
      "Mean Balanced Accuracy: 0.6516\n",
      "Mean F1-Score (Positive Class): 0.3715\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import f1_score, classification_report, balanced_accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "y_original = df['Class']\n",
    "groups = df['Info_group']\n",
    "le = LabelEncoder()\n",
    "y_final = le.fit_transform(y_original)\n",
    "\n",
    "print(\"--- Starting Optuna Tuning (Objective: Maximize F1-Score with Regularization) ---\")\n",
    "\n",
    "def objective(trial):\n",
    "   \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'lambda': trial.suggest_float('lambda', 1.0, 10.0, log=True), # L2 Regularization\n",
    "        'alpha': trial.suggest_float('alpha', 0, 5.0) # L1 Regularization\n",
    "    }\n",
    "    \n",
    "    pipeline = ImbPipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('adasyn', ADASYN(random_state=42)),\n",
    "        ('xgb', XGBClassifier(random_state=42, n_jobs=-1, **params))\n",
    "    ])\n",
    "    \n",
    "    scores = []\n",
    "    gkf = GroupKFold(n_splits=2)\n",
    "    for train_index, test_index in gkf.split(X_final, y_final, groups=groups):\n",
    "        X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "        y_train, y_test = y_final[train_index], y_final[test_index]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        scores.append(f1_score(y_test, preds, pos_label=1))\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=40) \n",
    "final_params = study.best_params\n",
    "\n",
    "print(\"\\n--- Optuna Tuning Complete ---\")\n",
    "print(f\"Best F1-Score Found: {study.best_value:.4f}\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(final_params)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "print(\"\\n--- Evaluating Best Regularized Model with Optimal Threshold ---\")\n",
    "final_pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('xgb', XGBClassifier(random_state=42, n_jobs=-1, **final_params))\n",
    "])\n",
    "\n",
    "all_f1_scores = []\n",
    "all_balanced_accuracies = []\n",
    "gkf_final = GroupKFold(n_splits=2)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gkf_final.split(X_final, y_final, groups)):\n",
    "    print(f\"\\n--- Fold {i+1}/2 ---\")\n",
    "    X_train, X_test = X_final.iloc[train_index], X_final.iloc[test_index]\n",
    "    y_train, y_test = y_final[train_index], y_final[test_index]\n",
    "\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "    y_pred_probs = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    f1s = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    best_threshold = thresholds[np.argmax(f1s)]\n",
    "    print(f\"Optimal Threshold for this fold: {best_threshold:.4f}\")\n",
    "    \n",
    "    y_pred_final = (y_pred_probs >= best_threshold).astype(int)\n",
    "    all_f1_scores.append(f1_score(y_test, y_pred_final, pos_label=1))\n",
    "    all_balanced_accuracies.append(balanced_accuracy_score(y_test, y_pred_final))\n",
    "\n",
    "    print(\"\\nFinal Classification Report (with optimal threshold):\")\n",
    "    print(classification_report(y_test, y_pred_final, zero_division=0))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFinal Model Performance Summary:\")\n",
    "print(f\"Mean Balanced Accuracy: {np.mean(all_balanced_accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score (Positive Class): {np.mean(all_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749de49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
